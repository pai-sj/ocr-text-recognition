{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import tensorflow as tf \n",
    "assert int(tf.__version__[:1]) < 2.0, \"해당 코드는 1.x에서만 동작합니다.\"\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\[ MNIST 데이터셋 - CRNN \\]\n",
    "\n",
    "MNIST 데이터셋을 통해 정상적으로 동작하는지를 확인해보도록 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import SerializationDataset\n",
    "\n",
    "train_set = SerializationDataset('mnist','train',\n",
    "                                 digit=5,pad_range=(3,10))\n",
    "validation_set = SerializationDataset('mnist','validation',\n",
    "                                      digit=5,pad_range=(3,10))\n",
    "test_set = SerializationDataset('mnist','test',\n",
    "                                digit=(3,8),pad_range=(3,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 Generator 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.generator import DataGenerator\n",
    "\n",
    "train_gen = DataGenerator(train_set, \n",
    "                          batch_size=32)\n",
    "valid_gen = DataGenerator(validation_set, \n",
    "                          batch_size=100, \n",
    "                          shuffle=False)\n",
    "test_gen = DataGenerator(test_set, \n",
    "                         batch_size=500, \n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.layers import ConvFeatureExtractor, Map2Sequence \n",
    "from models.layers import BLSTMEncoder, CTCDecoder\n",
    "from models.losses import ctc_loss\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 28\n",
    "num_classes = 10\n",
    "n_hidden = 16\n",
    "n_lstm = 256\n",
    "K.clear_session()\n",
    "\n",
    "# For Gray Scale Image & Dynamic width\n",
    "inputs = Input(shape=(height, None, 1),name='image')\n",
    "\n",
    "# CRNN Model\n",
    "conv_maps = ConvFeatureExtractor(n_hidden=n_hidden,\n",
    "                                 name='feature_extractor')(inputs)\n",
    "feature_seqs = Map2Sequence(name='map_to_sequence')(conv_maps)\n",
    "lstm_seqs = BLSTMEncoder(n_units=n_lstm)(feature_seqs)\n",
    "\n",
    "# 우리의 출력 형태는 class 수에 Blank Label을 하나 더해 #classes + 1 만큼을 출력\n",
    "output_seqs = Dense(num_classes+1,\n",
    "                    activation='softmax',\n",
    "                    name='output_seqs')(lstm_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.optimizer import AdamW\n",
    "\n",
    "# 모델 구성하기\n",
    "# (1) 학습 모델 구성하기\n",
    "y_true =  tf.placeholder(shape=(None,None), dtype=tf.int32)\n",
    "trainer = Model(inputs, output_seqs, name='trainer')\n",
    "trainer.compile('adam',\n",
    "                loss={\"output_seqs\":ctc_loss},\n",
    "                target_tensors=[y_true])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### caution\n",
    "\n",
    "`K.ctc_batch_cost`에 이용되는 Input Tensor의 Interface는 아래와 같습니다.\n",
    "\n",
    "* y_true: tensor `(samples, max_string_length)` containing the truth labels.\n",
    "* y_pred: tensor `(samples, time_steps, num_categories)` containing the prediction, or output of the softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) 예측 모델 구성하기\n",
    "predictions = CTCDecoder(beam_width=100)(output_seqs)\n",
    "predictor = Model(inputs, predictions[0], name='predictor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델  학습시키기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit_generator(train_gen,\n",
    "                      epochs=10,\n",
    "                      validation_data=valid_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, true_label in zip(*test_gen[0]):\n",
    "    result = predictor.predict(image[np.newaxis])\n",
    "    predict_seq = \"\".join([str(char) for char in result.ravel()])\n",
    "    plt.title(f'label : {predict_seq}')\n",
    "    plt.imshow(image[:,:,0])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
